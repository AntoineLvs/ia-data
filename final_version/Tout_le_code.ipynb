{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653b233f-b8fe-4de2-ab4f-4db08a5faa04",
   "metadata": {},
   "source": [
    "# Main app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d102fe93-25f2-422d-bc45-9605b81b5df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoine/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4639 images belonging to 21 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 10:05:58.351 Python[45277:11735074] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "2025-01-15 10:05:59.676 Python[45277:11735074] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import threading\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data processing and visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning / Computer Vision\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "import cv2\n",
    "\n",
    "# GUI\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Suppress warnings and TensorFlow logs\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Model paths and configurations\n",
    "MODEL_PATHS = {\n",
    "    'glasses': 'dataset_glasses_classification_model.h5',\n",
    "    'face': 'face_recognition_model.h5',\n",
    "    'hair': 'hair_detection_model.h5',\n",
    "    'hair_labels': 'hair_labels.npy'\n",
    "}\n",
    "\n",
    "# Detection settings\n",
    "DETECTION_CONFIG = {\n",
    "    'cooldown': timedelta(minutes=2),\n",
    "    'timeout': timedelta(seconds=2),\n",
    "    'required_detections': 5,\n",
    "    'confidence_threshold': 0.9\n",
    "}\n",
    "\n",
    "# Initialize detection variables\n",
    "last_detections = {}\n",
    "detection_buffer = {}\n",
    "log_file = \"detections_log.json\"\n",
    "\n",
    "# Load models\n",
    "glasses_model = load_model(MODEL_PATHS['glasses'])\n",
    "face_model = load_model(MODEL_PATHS['face'])\n",
    "hair_model = load_model(MODEL_PATHS['hair'])\n",
    "hair_labels = np.load(MODEL_PATHS['hair_labels'])\n",
    "\n",
    "# Initialize face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Data preparation\n",
    "data_dir = 'faces'\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_set = datagen.flow_from_directory(\n",
    "    data_dir, \n",
    "    target_size=(180, 180), \n",
    "    batch_size=32, \n",
    "    class_mode='categorical'\n",
    ")\n",
    "identity_labels = {v: k for k, v in train_set.class_indices.items()}\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# Threading variables\n",
    "frame_lock = threading.Lock()\n",
    "current_frame = None\n",
    "glasses_label = None\n",
    "predicted_label = None\n",
    "hair_color_label = None\n",
    "\n",
    "def train_model():\n",
    "    data_dir = 'faces'\n",
    "    batch_size = 32\n",
    "    img_height, img_width = 180, 180\n",
    "\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "    train_set = datagen.flow_from_directory(data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical', subset='training')\n",
    "    test_set = datagen.flow_from_directory(data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical', subset='validation')\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Rescaling(scale=1./255, input_shape=(img_height, img_width, 3)))\n",
    "    model.add(layers.Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(train_set.num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    epochs = 10\n",
    "    history = model.fit(train_set, validation_data=test_set, epochs=epochs)\n",
    "    model.save('face_recognition_model.h5')\n",
    "    print(\"Model training complete. Saved as 'face_recognition_model.h5'.\")\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "def advanced_face_detection():\n",
    "    # Global Variables for detections\n",
    "    last_detections = {}\n",
    "    log_file = \"detections_log.json\"\n",
    "    detection_cooldown = timedelta(minutes=2)\n",
    "    detection_buffer = {}\n",
    "    required_consistent_detections = 5\n",
    "    detection_timeout = timedelta(seconds=2)\n",
    "    confidence_threshold = 0.9\n",
    "\n",
    "    # Load Models\n",
    "    try:\n",
    "        glasses_model = load_model('dataset_glasses_classification_model.h5')\n",
    "        face_model = load_model('face_recognition_model.h5')\n",
    "        hair_model = load_model('hair_detection_model.h5')\n",
    "        hair_labels = np.load('hair_labels.npy')\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Erreur lors du chargement des modèles: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Variables for synchronisation\n",
    "    frame_lock = threading.Lock()\n",
    "    current_frame = None\n",
    "    glasses_label = None\n",
    "    predicted_label = None\n",
    "    hair_color_label = None\n",
    "    last_recognized_person = \"\"\n",
    "\n",
    "\n",
    "    def write_detection_log(identity, glasses_status, hair_color):\n",
    "        current_time = datetime.now()\n",
    "        if identity in last_detections:\n",
    "            if (current_time - last_detections[identity]) < detection_cooldown:\n",
    "                return\n",
    "        \n",
    "        last_detections[identity] = current_time\n",
    "        log_entry = {\n",
    "            \"timestamp\": current_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"identity\": identity,\n",
    "            \"glasses\": glasses_status,\n",
    "            \"hair_color\": hair_color\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            try:\n",
    "                with open(log_file, 'r') as f:\n",
    "                    logs = json.load(f)\n",
    "            except FileNotFoundError:\n",
    "                logs = []\n",
    "            logs.append(log_entry)\n",
    "            with open(log_file, 'w') as f:\n",
    "                json.dump(logs, f, indent=4)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'écriture des logs: {e}\")\n",
    "\n",
    "    def detect_glasses_and_identity():\n",
    "        nonlocal glasses_label, predicted_label, last_recognized_person\n",
    "        while True:\n",
    "            with frame_lock:\n",
    "                if current_frame is None:\n",
    "                    continue\n",
    "                frame = current_frame.copy()\n",
    "\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=7, minSize=(50, 50))\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                face = frame[y:y+h, x:x+w]\n",
    "\n",
    "                # Glasses detections\n",
    "                resized_face_glasses = cv2.resize(face, (128, 128))\n",
    "                normalized_face_glasses = resized_face_glasses / 255.0\n",
    "                input_face_glasses = np.expand_dims(normalized_face_glasses, axis=0)\n",
    "                glasses_prediction = glasses_model.predict(input_face_glasses, verbose=0)\n",
    "                glasses_label = \"Glasses\" if glasses_prediction[0] <= 0.5 else \"No Glasses\"\n",
    "\n",
    "                # Identity recognition\n",
    "                resized_face_identity = cv2.resize(face, (180, 180))\n",
    "                normalized_face_identity = resized_face_identity / 255.0\n",
    "                input_face_identity = np.expand_dims(normalized_face_identity, axis=0)\n",
    "                identity_predictions = face_model.predict(input_face_identity, verbose=0)\n",
    "                \n",
    "                confidence = np.max(identity_predictions[0])\n",
    "                predicted_index = np.argmax(identity_predictions[0])\n",
    "                \n",
    "                if confidence >= confidence_threshold:\n",
    "                    current_identity = identity_labels[predicted_index]\n",
    "                    current_time = datetime.now()\n",
    "                    \n",
    "                    if current_identity in detection_buffer:\n",
    "                        detection_buffer[current_identity] = [\n",
    "                            (time, ident, glasses, hair) \n",
    "                            for time, ident, glasses, hair in detection_buffer[current_identity] \n",
    "                            if current_time - time < detection_timeout\n",
    "                        ]\n",
    "                    \n",
    "                    if current_identity not in detection_buffer:\n",
    "                        detection_buffer[current_identity] = []\n",
    "                    detection_buffer[current_identity].append(\n",
    "                        (current_time, current_identity, glasses_label, hair_color_label)\n",
    "                    )\n",
    "                    \n",
    "                    if len(detection_buffer[current_identity]) >= required_consistent_detections:\n",
    "                        predicted_label = current_identity\n",
    "                        last_recognized_person = current_identity\n",
    "                        write_detection_log(\n",
    "                            identity=current_identity,\n",
    "                            glasses_status=glasses_label,\n",
    "                            hair_color=hair_color_label\n",
    "                        )\n",
    "                        detection_buffer[current_identity] = []\n",
    "                    else:\n",
    "                        predicted_label = \"Verification...\"\n",
    "                else:\n",
    "                    predicted_label = \"Inconnu\"\n",
    "\n",
    "    def detect_hair_color():\n",
    "        nonlocal hair_color_label\n",
    "        while True:\n",
    "            with frame_lock:\n",
    "                if current_frame is None:\n",
    "                    continue\n",
    "                frame = current_frame.copy()\n",
    "\n",
    "            resized_frame = cv2.resize(frame, (224, 224))\n",
    "            input_frame = preprocess_input(np.expand_dims(resized_frame, axis=0))\n",
    "            predictions = hair_model.predict(input_frame, verbose=0)\n",
    "            hair_color_label = hair_labels[np.argmax(predictions)]\n",
    "\n",
    "    # Start threads\n",
    "    glasses_and_identity_thread = threading.Thread(target=detect_glasses_and_identity, daemon=True)\n",
    "    hair_color_thread = threading.Thread(target=detect_hair_color, daemon=True)\n",
    "\n",
    "    glasses_and_identity_thread.start()\n",
    "    hair_color_thread.start()\n",
    "\n",
    "    # Video Capture\n",
    "    cap = cv2.VideoCapture(1)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        with frame_lock:\n",
    "            current_frame = frame.copy()\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=7, minSize=(50, 50))\n",
    "\n",
    "        cv2.putText(frame, f\"Last Person Recognised: {last_recognized_person}\", \n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            labels = [predicted_label, glasses_label, hair_color_label]\n",
    "            for i, label in enumerate(labels):\n",
    "                if label:  # Vérifier que le label n'est pas None\n",
    "                    cv2.putText(frame, str(label), (x, y - 10 - (i * 30)), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Reconnaissance Faciale\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def add_face():\n",
    "    def start_capture():\n",
    "        name = name_entry.get().strip()\n",
    "        if not name:\n",
    "            messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "            return\n",
    "        \n",
    "        person_folder = os.path.join('faces', name)\n",
    "        if os.path.exists(person_folder):\n",
    "            message = f\"Adding pictures to the existing folder for {name}.\"\n",
    "        else:\n",
    "            message = f\"Creating a new folder for {name}.\"\n",
    "            os.makedirs(person_folder, exist_ok=True)\n",
    "\n",
    "        capture_window.destroy()  # Close the name entry window\n",
    "\n",
    "        cap = cv2.VideoCapture(1)\n",
    "\n",
    "        # Display the message on the camera feed\n",
    "        for i in range(3, 0, -1):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.putText(frame, message, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            frame = cv2.putText(frame, f\"Capturing in {i}...\", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.imshow(\"Add New Face\", frame)\n",
    "            cv2.waitKey(1000)  # Wait for 1 second per countdown step\n",
    "\n",
    "        print(\"Press 'SPACE' to stop capturing photos.\")\n",
    "        count = len(os.listdir(person_folder))  # Start from the next available file number\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(\n",
    "                gray, scaleFactor=1.1, minNeighbors=7, minSize=(50, 50)\n",
    "            )  # Increased minNeighbors and added minSize\n",
    "            for (x, y, w, h) in faces:\n",
    "                if w < 50 or h < 50:  # Skip faces that are too small\n",
    "                    continue\n",
    "                face = frame[y:y+h, x:x+w]\n",
    "                face_path = os.path.join(person_folder, f\"{name}_{count}.jpg\")\n",
    "                cv2.imwrite(face_path, face)\n",
    "                count += 1\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            frame = cv2.putText(frame, \"Press 'SPACE' to stop\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.imshow(\"Add New Face\", frame)\n",
    "\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == 32:  # Spacebar\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"Saved {count - len(os.listdir(person_folder))} new photos for {name}.\")\n",
    "\n",
    "    # Create a new window to input the name\n",
    "    capture_window = tk.Tk()\n",
    "    capture_window.title(\"Add a New Person\")\n",
    "    capture_window.geometry(\"300x200\")\n",
    "\n",
    "    tk.Label(capture_window, text=\"Enter Name:\", font=(\"Helvetica\", 12)).pack(pady=10)\n",
    "    name_entry = tk.Entry(capture_window, font=(\"Helvetica\", 12))\n",
    "    name_entry.pack(pady=10)\n",
    "\n",
    "    tk.Button(capture_window, text=\"Start Capture\", font=(\"Helvetica\", 12), command=start_capture).pack(pady=20)\n",
    "    capture_window.mainloop()\n",
    "    \n",
    "# Main Menu\n",
    "def open_main_menu():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Face Recognition App\")\n",
    "    root.geometry(\"400x400\")\n",
    "\n",
    "    tk.Label(root, text=\"Face Recognition App\", font=(\"Helvetica\", 16)).pack(pady=20)\n",
    "    tk.Button(root, text=\"Add a New Person\", font=(\"Helvetica\", 14), command=lambda: [root.destroy(), add_face()]).pack(pady=20)\n",
    "    tk.Button(root, text=\"Start Advanced Detection\", font=(\"Helvetica\", 14), command=lambda: [root.destroy(), advanced_face_detection()]).pack(pady=20)\n",
    "    tk.Button(root, text=\"Train Model\", font=(\"Helvetica\", 14), command=lambda: [root.destroy(), train_model()]).pack(pady=20)\n",
    "    tk.Button(root, text=\"Exit\", font=(\"Helvetica\", 14), command=root.quit).pack(pady=20)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "# Run the menu\n",
    "if __name__ == \"__main__\":\n",
    "    open_main_menu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83eb00-97bb-4b40-806a-0e7149bd0b92",
   "metadata": {},
   "source": [
    "# Second App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8806be71-51e0-4fdb-a3ab-9bc0d5e8d49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2604 images belonging to 21 classes.\n",
      "Found 641 images belonging to 21 classes.\n",
      "Number of classes: 21\n",
      "Training batch shape: (32, 180, 180, 3) (32, 21)\n",
      "Validation batch shape: (32, 180, 180, 3) (32, 21)\n",
      "Epoch 1/10\n",
      "\u001b[1m42/82\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - accuracy: 0.1039 - loss: 3.0019"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c04031-67be-44b8-99c8-a57178805ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

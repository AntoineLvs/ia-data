{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3692 images belonging to 22 classes.\n",
      "WARNING:tensorflow:5 out of the last 36 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x34f13b4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 36 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x34f13b4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import threading\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Ajouter après les variables globales\n",
    "last_detections = {}  # Dictionnaire pour stocker la dernière détection de chaque personne\n",
    "log_file = \"detections_log.json\"\n",
    "detection_cooldown = timedelta(minutes=2)\n",
    "# Charger les modèles\n",
    "glasses_model = load_model('glasses_classification_model.h5')\n",
    "face_model = load_model('face_recognition_model.h5')\n",
    "hair_model = load_model('hair_detection_model.h5')\n",
    "hair_labels = np.load('hair_labels.npy')\n",
    "\n",
    "# Ajouter après les variables globales existantes\n",
    "detection_buffer = {}  # Pour stocker les dernières détections\n",
    "required_consistent_detections = 5  # Nombre de détections cohérentes requises\n",
    "detection_timeout = timedelta(seconds=2)  # Temps maximum pour accumuler les détections\n",
    "\n",
    "# Charger Haar Cascade pour la détection des visages\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Préparer les labels d'identité\n",
    "data_dir = 'faces'  # Répertoire contenant les images classées\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_set = datagen.flow_from_directory(data_dir, target_size=(180, 180), batch_size=32, class_mode='categorical')\n",
    "identity_labels = {v: k for k, v in train_set.class_indices.items()}\n",
    "\n",
    "# Capture vidéo\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# Variables pour synchronisation des threads\n",
    "frame_lock = threading.Lock()\n",
    "current_frame = None\n",
    "glasses_label = None\n",
    "predicted_label = None\n",
    "hair_color_label = None\n",
    "\n",
    "# Seuil de confiance pour la reconnaissance faciale\n",
    "confidence_threshold = 0.9\n",
    "\n",
    "# Fonction pour écrire les logs\n",
    "def write_detection_log(identity, glasses_status, hair_color):\n",
    "    current_time = datetime.now()\n",
    "    \n",
    "    # Vérifier si la personne a déjà été détectée récemment\n",
    "    if identity in last_detections:\n",
    "        if (current_time - last_detections[identity]) < detection_cooldown:\n",
    "            return  # Skip si détection trop récente\n",
    "    \n",
    "    # Mettre à jour le timestamp de dernière détection\n",
    "    last_detections[identity] = current_time\n",
    "    \n",
    "    # Préparer les données du log\n",
    "    log_entry = {\n",
    "        \"timestamp\": current_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"identity\": identity,\n",
    "        \"glasses\": glasses_status,\n",
    "        \"hair_color\": hair_color\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Charger les logs existants\n",
    "        try:\n",
    "            with open(log_file, 'r') as f:\n",
    "                logs = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            logs = []\n",
    "        \n",
    "        # Ajouter la nouvelle entrée\n",
    "        logs.append(log_entry)\n",
    "        \n",
    "        # Sauvegarder les logs\n",
    "        with open(log_file, 'w') as f:\n",
    "            json.dump(logs, f, indent=4)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'écriture des logs: {e}\")\n",
    "\n",
    "\n",
    "def detect_glasses_and_identity():\n",
    "    global glasses_label, predicted_label\n",
    "    while True:\n",
    "        with frame_lock:\n",
    "            if current_frame is None:\n",
    "                continue\n",
    "            frame = current_frame.copy()\n",
    "\n",
    "\n",
    "        # Convertir en niveaux de gris pour la détection des visages\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=7, minSize=(50, 50))\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Préparation pour la détection de lunettes\n",
    "            resized_face_glasses = cv2.resize(face, (128, 128))\n",
    "            normalized_face_glasses = resized_face_glasses / 255.0\n",
    "            input_face_glasses = np.expand_dims(normalized_face_glasses, axis=0)\n",
    "            glasses_prediction = glasses_model.predict(input_face_glasses, verbose=0)\n",
    "            glasses_label = \"Glasses\" if glasses_prediction[0] <= 0.5 else \"No Glasses\"\n",
    "\n",
    "            # Préparation pour la reconnaissance d'identité\n",
    "            resized_face_identity = cv2.resize(face, (180, 180))\n",
    "            normalized_face_identity = resized_face_identity / 255.0\n",
    "            input_face_identity = np.expand_dims(normalized_face_identity, axis=0)\n",
    "            identity_predictions = face_model.predict(input_face_identity, verbose=0)\n",
    " # Après la prédiction d'identité\n",
    "            confidence = np.max(identity_predictions[0])\n",
    "            predicted_index = np.argmax(identity_predictions[0])\n",
    "            \n",
    "            if confidence >= confidence_threshold:\n",
    "                current_identity = identity_labels[predicted_index]\n",
    "                current_time = datetime.now()\n",
    "                \n",
    "                # Nettoyer les anciennes détections\n",
    "                if current_identity in detection_buffer:\n",
    "                    detection_buffer[current_identity] = [\n",
    "                        (time, ident, glasses, hair) \n",
    "                        for time, ident, glasses, hair in detection_buffer[current_identity] \n",
    "                        if current_time - time < detection_timeout\n",
    "                    ]\n",
    "                \n",
    "                # Ajouter la nouvelle détection\n",
    "                if current_identity not in detection_buffer:\n",
    "                    detection_buffer[current_identity] = []\n",
    "                detection_buffer[current_identity].append(\n",
    "                    (current_time, current_identity, glasses_label, hair_color_label)\n",
    "                )\n",
    "                \n",
    "                # Vérifier si nous avons assez de détections cohérentes\n",
    "                if len(detection_buffer[current_identity]) >= required_consistent_detections:\n",
    "                    predicted_label = current_identity\n",
    "                    # Écrire dans les logs seulement si nous avons assez de détections cohérentes\n",
    "                    write_detection_log(\n",
    "                        identity=current_identity,\n",
    "                        glasses_status=glasses_label,\n",
    "                        hair_color=hair_color_label\n",
    "                    )\n",
    "                    # Réinitialiser le buffer après une détection réussie\n",
    "                    detection_buffer[current_identity] = []\n",
    "                else:\n",
    "                    predicted_label = \"Verification...\"\n",
    "            else:\n",
    "                predicted_label = \"Inconnu\"\n",
    "\n",
    "\n",
    "def detect_hair_color():\n",
    "    global hair_color_label\n",
    "    while True:\n",
    "        with frame_lock:\n",
    "            if current_frame is None:\n",
    "                continue\n",
    "            frame = current_frame.copy()\n",
    "\n",
    "        # Prétraitement de l'image pour la détection de la couleur des cheveux\n",
    "        resized_frame = cv2.resize(frame, (224, 224))\n",
    "        input_frame = preprocess_input(np.expand_dims(resized_frame, axis=0))\n",
    "\n",
    "        # Prédiction de la couleur des cheveux\n",
    "        predictions = hair_model.predict(input_frame, verbose=0)\n",
    "        hair_color_label = hair_labels[np.argmax(predictions)]\n",
    "\n",
    "\n",
    "# Lancer les threads\n",
    "glasses_and_identity_thread = threading.Thread(target=detect_glasses_and_identity, daemon=True)\n",
    "hair_color_thread = threading.Thread(target=detect_hair_color, daemon=True)\n",
    "\n",
    "glasses_and_identity_thread.start()\n",
    "hair_color_thread.start()\n",
    "\n",
    "# Boucle principale\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    with frame_lock:\n",
    "        current_frame = frame.copy()\n",
    "\n",
    "    # Détecter les visages pour afficher les informations\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=7, minSize=(50, 50))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Dessiner un carré autour du visage\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Afficher les informations les unes sous les autres\n",
    "        labels = [predicted_label, glasses_label, hair_color_label]\n",
    "        for i, label in enumerate(labels):\n",
    "            cv2.putText(frame, label, (x, y - 10 - (i * 30)), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Reconnaissance Faciale\", frame)\n",
    "\n",
    "    # Quitter avec la touche 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
